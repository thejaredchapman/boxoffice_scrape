from email import header
from tracemalloc import start
import requests
from requests_html import HTML
import datetime
import pandas as pd
import os
import sys

now = datetime.datetime.now()
year = now.year
start_year = now.year

BASE_DIR = os.path.dirname(__file__)

# Saving Data
def url_to_txt(url, filename="world.html", save=False):
    r = requests.get(url)
    if r.status_code == 200:
        html_text = r.text
        if save:
            with open(f"world-{year}.html", 'w') as f:
             f.write(html_text)
        return html_text
    return ""

url = "https://www.boxofficemojo.com/year/world/?ref_=bo_nb_hm_tab"

# Parsing and and extracting
def parse_and_extract(url, name="current_global_boxoffice"):

    html_text = url_to_txt(url)
    if html_text == None:
        return False
    r_html = HTML(html=html_text)
    table_class = ".imdb-scroll-table"
    # table_class = "#table"
    r_table = r_html.find(table_class)

    #print(r_table)
    table_data = []
    table_data_dicts = []
    header_names = []
    if len(r_table) == 0:
        return False
    print(r_table[0].text)
    parsed_table = r_table[0]
    rows = parsed_table.find("tr")
    header_row = rows[0]
    header_cols = header_row.find('th')
    header_names = [x.text for x in header_cols]
    for row in rows[1:]:
        #print(row.text)
        cols = row.find("td")
        row_data = []
        #row_dict_data = {}
        for i, col in enumerate(cols):
            header_name = header_names[i]
            #row_data_dict[header_name] = col.text
            row_data.append(col.text)
        #table_data_dicts.append(row_dict_data)
        table_data.append(row_data)
    # Make directory called data 
    df = pd.DataFrame(table_data, columns=header_names)
    # df = pd.DataFrame(table_data_dicts)
    path = os.path.join(BASE_DIR, 'data')
    os.makedirs(path, exist_ok=True)
    filepath = os.path.join('data', f'{name}.csv')
    df.to_csv(f'data/{name}.csv', index=False) 
    return True

# Which year to scrape
def run(start_year, years_ago = 10):
    if start_year == None:
        now = datetime.datetime.now()
        start_year = now.year
    assert isinstance(start_year, int)
    assert len(f"{start_year}") == 4
    for i in range(0, years_ago+1):
        url = f"https://www.boxofficemojo.com/year/world/{start_year}"
        finished = parse_and_extract(url, name=start_year)
        if finished:
            print(f"Finish {start_year}")
        else:
            print(f"{start_year}not finished")
        start_year -= 1

if __name__ == "__main__":
    start, count = sys.argv[1], sys.argv[2]
    try:
        start = int(start)
    except:
        start = None
    try:
        count = int(count)
    except:
        count = 1
    
    run(start_year, years_ago = 10)

# to start file, enter file name with range of years for argument. for example 2010 - 2020, "python scrape_movies 2010 2020"
